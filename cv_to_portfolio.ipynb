{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xbVjjzF0piDE"
      },
      "outputs": [],
      "source": [
        "!pip install crewai[tools]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install crewai\n",
        "!pip install python-docx\n",
        "!pip install pdfminer.six"
      ],
      "metadata": {
        "id": "d3eoyeOasTQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "W3Ogu5O24sbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import litellm\n",
        "from google.colab import userdata\n",
        "litellm.api_key = userdata.get(\"GOOGLE_API_KEY\")\n",
        "\n",
        "llm=\"gemini/gemini-1.5-flash-exp-0827\""
      ],
      "metadata": {
        "id": "Tf83gi88pwU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfplumber"
      ],
      "metadata": {
        "id": "_spXJbGr3E77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "import litellm\n",
        "from crewai import Agent, Task, Crew, Process\n",
        "from crewai_tools import SerperDevTool\n",
        "import pdfplumber\n",
        "from docx import Document\n",
        "import gradio as gr\n",
        "\n",
        "# Set up API keys\n",
        "litellm.api_key = userdata.get(\"GOOGLE_API_KEY\")\n",
        "os.environ['SERPER_API_KEY'] = userdata.get('SERPER_API_KEY')\n",
        "\n",
        "# Define the LLM\n",
        "llm = \"gemini/gemini-1.5-flash-exp-0827\"  # Your LLM model\n",
        "\n",
        "# Initialize the tool for internet searching capabilities\n",
        "tool = SerperDevTool()\n",
        "\n",
        "# Create the CV Analysis Agent\n",
        "cv_analysis_agent = Agent(\n",
        "    role=\"CV Analyzer\",\n",
        "    goal='Analyze the given CV and extract key skills and experiences and make improvements if needed for portfolio creation.',\n",
        "    verbose=True,\n",
        "    memory=True,\n",
        "    backstory=(\n",
        "        \"As a CV Analyzer, you are skilled in identifying key information \"\n",
        "        \"from resumes to aid in building effective portfolios.\"\n",
        "        \"You can add relevant skills and job responsibilities evaluating the whole cv.\"\n",
        "    ),\n",
        "    tools=[tool],\n",
        "    llm=llm,\n",
        "    allow_delegation=True\n",
        ")\n",
        "\n",
        "# Create the Portfolio Generation Agent\n",
        "portfolio_generation_agent = Agent(\n",
        "    role='Portfolio Generator',\n",
        "    goal='Generate a beautiful static HTML/CSS/JS landing portfolio webpage based on CV analysis.',\n",
        "    verbose=True,\n",
        "    memory=True,\n",
        "    backstory=(\n",
        "        \"As a Portfolio Generator, you craft engaging web pages with effective functionalities and color combinations \"\n",
        "        \"to showcase individual talents and experiences with the best user experience.\"\n",
        "    ),\n",
        "    tools=[tool],\n",
        "    llm=llm,\n",
        "    allow_delegation=False\n",
        ")\n",
        "\n",
        "# Research task for CV analysis\n",
        "cv_analysis_task = Task(\n",
        "    description=(\n",
        "        \"Analyze the provided {cv} and identify key skills, experiences, \"\n",
        "        \"and accomplishments. Highlight notable projects and educational background.\"\n",
        "    ),\n",
        "    expected_output='A summary of skills, experiences, and projects formatted for a portfolio.',\n",
        "    tools=[tool],\n",
        "    agent=cv_analysis_agent,\n",
        ")\n",
        "\n",
        "# Writing task for portfolio generation with enhanced UI requirements\n",
        "portfolio_task = Task(\n",
        "    description=(\n",
        "        \"Generate a static HTML/CSS/JS landing portfolio with a name as header in top, navbar for different sections, beautiful and responsive design. \"\n",
        "        \"Ensure that the layout is clean, with sections for skills, projects, experiences, certifications, publications, and contact details if present in the CV. \"\n",
        "        \"Include a footer that does not overlap with the content. \"\n",
        "        \"Use a modern color palette and incorporate CSS frameworks if necessary, \"\n",
        "        \"but provide everything embedded in the HTML file. \"\n",
        "        \"The output should be a complete HTML document starting from <html> to </html>, ready to deploy.\"\n",
        "    ),\n",
        "    expected_output='A complete HTML/CSS/JS code content only for a portfolio website in a single .html file',\n",
        "    tools=[tool],\n",
        "    agent=portfolio_generation_agent,\n",
        "    async_execution=False,\n",
        "    output_file='portfolio.html'  # Output as HTML file\n",
        ")\n",
        "\n",
        "# Function to read CV from PDF or DOCX file\n",
        "def read_cv_file(file_path):\n",
        "    ext = os.path.splitext(file_path)[1].lower()\n",
        "    cv_content = \"\"\n",
        "\n",
        "    if ext == '.pdf':\n",
        "        with pdfplumber.open(file_path) as pdf:\n",
        "            for page in pdf.pages:\n",
        "                cv_content += page.extract_text()\n",
        "    elif ext == '.docx':\n",
        "        doc = Document(file_path)\n",
        "        for para in doc.paragraphs:\n",
        "            cv_content += para.text + \"\\n\"\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format. Please use .pdf or .docx.\")\n",
        "\n",
        "    return cv_content.strip()\n",
        "\n",
        "# Create a Crew for processing\n",
        "crew = Crew(\n",
        "    agents=[cv_analysis_agent, portfolio_generation_agent],\n",
        "    tasks=[cv_analysis_task, portfolio_task],\n",
        "    process=Process.sequential,\n",
        ")\n",
        "\n",
        "# Function to process CV and generate portfolio\n",
        "import re\n",
        "\n",
        "# Function to process CV and generate portfolio\n",
        "def process_cv(file):\n",
        "    try:\n",
        "        cv_file_content = read_cv_file(file.name)\n",
        "        result = crew.kickoff(inputs={'cv': cv_file_content})\n",
        "\n",
        "        # Print the entire result object to explore its contents (for debugging)\n",
        "        print(result)\n",
        "\n",
        "        # Convert the result to string\n",
        "        html_output = str(result)\n",
        "\n",
        "        # Use replace to remove '''html''' and ''' from the output\n",
        "        clean_html_output = html_output.replace(\"'''html'''\", '').replace(\"'''\", '').strip()\n",
        "\n",
        "        return clean_html_output  # Return the cleaned HTML\n",
        "    except Exception as e:\n",
        "        return f\"Error: {e}\"\n",
        "\n",
        "# Gradio UI using Blocks\n",
        "with gr.Blocks() as iface:\n",
        "    gr.Markdown(\"# CV-2-HTML AI Enhanced Portfolio Website Generation\")\n",
        "    gr.Markdown(\"Upload your CV in PDF or DOCX format to analyze its content and generate a portfolio.\")\n",
        "\n",
        "    # File input for uploading CV\n",
        "    cv_input = gr.File(label=\"Upload your CV (.pdf or .docx)\")\n",
        "\n",
        "    # Output textbox for generated HTML\n",
        "    output_textbox = gr.Textbox(label=\"Generated HTML\", lines=20, placeholder=\"Your generated HTML will appear here...\", interactive=True)\n",
        "\n",
        "    # Process button\n",
        "    process_button = gr.Button(\"Generate Portfolio\")\n",
        "\n",
        "    # Define the button actions\n",
        "    process_button.click(fn=process_cv, inputs=cv_input, outputs=output_textbox)\n",
        "\n",
        "# Launch the Gradio interface\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "id": "ObZ2h6xr4pPp",
        "outputId": "c29d931b-8624-4b36-afe3-913ff960b028"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://27d3bcaea65b4091b4.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://27d3bcaea65b4091b4.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    }
  ]
}